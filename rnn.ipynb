{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4b7aaf-d09b-4b64-91e6-dee2976ce379",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16f89b44-fede-422c-b525-9a267aad4d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import datasets\n",
    "import numpy as np\n",
    "import transformers\n",
    "import datetime\n",
    "import os\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import tensorflow_datasets as tfds\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from pathlib import Path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d400cd26-730e-4c4e-aaed-5987f78ef5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730980886.120714  227453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730980886.169429  227453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730980886.169494  227453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49d12b0-ef16-422b-9edb-57b4f8a03a8c",
   "metadata": {},
   "source": [
    "# Global params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14c248b9-5820-47f2-93eb-85ce1ccaacb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "OUTPUT = 28\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60f89c7-209d-4ba7-b5f7-5d793b498f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb9f8d-1cf5-4954-8b70-18d47dee46e3",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8cc56a-5c94-4134-902d-e74edf1414aa",
   "metadata": {},
   "source": [
    "Load the dataset (we will be using [go_emotions](https://huggingface.co/datasets/google-research-datasets/go_emotions)). Pretokenize data or make a loader that tokenizes the sentenses as you iterate through the dataset. Implement two datasets: variable and fixed sentence length (in tokens). Don't forget to split the dataset into train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fea15226-0e61-4fcd-a188-d6330e545465",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('google-research-datasets/go_emotions', name='raw', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8f4e14-e7f9-42db-b86a-a54b412bec35",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'id',\n",
       " 'author',\n",
       " 'subreddit',\n",
       " 'link_id',\n",
       " 'parent_id',\n",
       " 'created_utc',\n",
       " 'rater_id',\n",
       " 'example_very_unclear',\n",
       " 'admiration',\n",
       " 'amusement',\n",
       " 'anger',\n",
       " 'annoyance',\n",
       " 'approval',\n",
       " 'caring',\n",
       " 'confusion',\n",
       " 'curiosity',\n",
       " 'desire',\n",
       " 'disappointment',\n",
       " 'disapproval',\n",
       " 'disgust',\n",
       " 'embarrassment',\n",
       " 'excitement',\n",
       " 'fear',\n",
       " 'gratitude',\n",
       " 'grief',\n",
       " 'joy',\n",
       " 'love',\n",
       " 'nervousness',\n",
       " 'optimism',\n",
       " 'pride',\n",
       " 'realization',\n",
       " 'relief',\n",
       " 'remorse',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'neutral']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b144fe06-9838-4812-9e19-9b74e903bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity',\n",
    "    'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',\n",
    "    'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief',\n",
    "    'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "682d6798-62fe-4d5c-8b8b-99394df534ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cd1e92c-57c8-4703-8db7-0da849a2e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(item):\n",
    "    item['lables'] = [item[key] for key in emotions]\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b814c9e9-f1c9-4768-981f-839ac99723d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / test split\n",
    "\n",
    "def get_train_test(dataset: datasets.arrow_dataset.Dataset):\n",
    "    dataset_splited = dataset.train_test_split(test_size=0.1)\n",
    "    split_labels    = ['train', 'test']\n",
    "\n",
    "    def get_process_data(split_label: str):\n",
    "        data = dataset_splited[split_label]\n",
    "        \n",
    "        process_data = data.map(lambda item: tokenizer(item['text'], padding='max_length', max_length=64, truncation=True), batched=True)\n",
    "        process_data = process_data.map(get_target)\n",
    "        \n",
    "        tf_ds = process_data.to_tf_dataset(\n",
    "            columns=[\"input_ids\"],\n",
    "            label_cols=[\"lables\"],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=(split_label == 'train'),\n",
    "        )\n",
    "\n",
    "        return tf_ds\n",
    "\n",
    "    return map(get_process_data, split_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6515e0b4-b032-474e-87e9-49866f8b6078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/tf/lib/python3.10/site-packages/datasets/arrow_dataset.py:403: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n",
      "I0000 00:00:1730980913.372793  227453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730980913.372884  227453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730980913.372927  227453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730980913.550533  227453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730980913.550625  227453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-07 22:01:53.550636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1730980913.550696  227453 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-07 22:01:53.550716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1414 MB memory:  -> device: 0, name: NVIDIA GeForce GT 1030, pci bus id: 0000:09:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# train, test = get_train_test(dataset)\n",
    "train, test = get_train_test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0942fb4-c6de-497a-a08b-74d81b951a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14253   510   477   465  3404   290  1234   340  2354   262  3420 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256 50256\n",
      " 50256 50256 50256 50256]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "ind = 0\n",
    "for item in test.as_numpy_iterator():\n",
    "    if ind < 1:\n",
    "        print(item[0][0])\n",
    "        print(item[1][0])\n",
    "    else: \n",
    "        break\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b628be8-1f04-4212-9392-dee3e207f532",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066591d4-60c1-4918-85e7-fafe734d1804",
   "metadata": {},
   "source": [
    "Implement your model. The model should have the RNN architecture (with LSTM or GRU cells), support stacking and bidirectional feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e54e3784-2f24-42a2-a8a0-164378480a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(prefix: str | None = None, suffix: str | None = None, separator: str = '_') -> str | None:\n",
    "    return prefix and prefix + separator + suffix or suffix or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90a144e0-b2f7-41a9-8f4f-4a84f40d6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(\n",
    "    units: int,\n",
    "    n_tokens: int,\n",
    "    n_labels: int,\n",
    "    n_stacks: int = 1,\n",
    "    bidirectional: bool = False,\n",
    "    name: str | None = None,\n",
    "    cell_type: type[keras.layers.Layer] = keras.layers.LSTMCell\n",
    ") -> keras.Model:\n",
    "    def apply_rnn(x):\n",
    "        rnn_layer_template = keras.layers.LSTM(units, name=get_name(name, 'lstm'))\n",
    "        \n",
    "        rnn_layer = rnn_layer_template\n",
    "\n",
    "        if bidirectional:\n",
    "            rnn_layer = keras.layers.Bidirectional(rnn_layer_template)\n",
    "\n",
    "            if n_stacks > 1:\n",
    "                new_x = keras.layers.Bidirectional(keras.layers.LSTM(units, return_sequences=True, name=get_name(name, 'lstm')))(x)\n",
    "                return keras.layers.Bidirectional(rnn_layer_template)(new_x)\n",
    "            else:\n",
    "                return rnn_layer(x)\n",
    "            \n",
    "        elif n_stacks > 1:\n",
    "            rnn_cells = [cell_type(units) for _ in range(n_stacks)]\n",
    "            stacked_lstm = keras.layers.StackedRNNCells(rnn_cells)\n",
    "            rnn_layer = keras.layers.RNN(stacked_lstm)\n",
    "\n",
    "            return rnn_layer(x)\n",
    "        else:\n",
    "            return rnn_layer(x)\n",
    "\n",
    "    \n",
    "\n",
    "    inputs = keras.layers.Input((None, ), dtype=tf.int32, name=get_name(name, 'inputs_tokens'))\n",
    "    x = keras.layers.Embedding(n_tokens, 64, name=get_name(name, 'embedding'))(inputs)\n",
    "    x = apply_rnn(x)\n",
    "    outputs = keras.layers.Dense(n_labels, activation=\"sigmoid\", name=get_name(name, 'prediction'))(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790d12f-d3f9-477e-bbfc-067baadf33c6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42397b6a-e849-4179-a359-647e902300f4",
   "metadata": {},
   "source": [
    "Train several models on the two dataset variants. Use either of the cell types (LSTM or GRU)\n",
    "* Simple RNN (no stacking, one direction)\n",
    "* Stacked RNN (stacking, one direction)\n",
    "* Bidirectional RNN (no stacking, bidirectional)\n",
    "* Stacked Bidirectional RNN (stacking, bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e640a6cc-5c38-429d-887e-20d2a632b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_params = [\n",
    "    {\n",
    "        'units': 32,\n",
    "        'name': 'simple_lstm',\n",
    "        'bidirectional': False,\n",
    "        'n_stacks': 1,\n",
    "        'cell_type': keras.layers.LSTMCell,\n",
    "    },\n",
    "    {\n",
    "        'units': 32,\n",
    "        'name': 'stacked_lstm',\n",
    "        'bidirectional': False,\n",
    "        'n_stacks': 2,\n",
    "        'cell_type': keras.layers.LSTMCell,\n",
    "    },\n",
    "    {\n",
    "        'units': 32,\n",
    "        'name': 'bidirectional_lstm',\n",
    "        'bidirectional': True,\n",
    "        'n_stacks': 1,\n",
    "        'cell_type': keras.layers.LSTMCell,\n",
    "    },\n",
    "    {\n",
    "        'units': 32,\n",
    "        'name': 'bidirectional_stacked_lstm',\n",
    "        'bidirectional': True,\n",
    "        'n_stacks': 2,\n",
    "        'cell_type': keras.layers.LSTMCell,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a71e161d-5e01-4d4e-8027-4a5a8838c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    get_model(\n",
    "        units=model['units'],\n",
    "        n_tokens=len(tokenizer.get_vocab()),\n",
    "        n_labels=len(emotions),\n",
    "        name=model['name'],\n",
    "        bidirectional=model['bidirectional'],\n",
    "        n_stacks=model['n_stacks'],\n",
    "        cell_type=model['cell_type']\n",
    "    )\n",
    "    for model in models_params\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92142b18-0255-416d-812b-b2cce689196a",
   "metadata": {},
   "source": [
    "Which loss should be used to multilabel classification? Which metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3493fca9-bd27-4ae1-845e-13a621cc06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.compile(\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate=0.001\n",
    "        ),\n",
    "        metrics=[\n",
    "            'binary_accuracy'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d467080f-9858-48c3-9db3-4fb87da4f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY_DIR = './history'\n",
    "os.makedirs(HISTORY_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a502505-0d47-462c-b5f1-ce0a05c9debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(HISTORY_DIR, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e056f4d7-9a52-46f7-8bf2-5ec654aae0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(model_name: str):\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(logdir, f'model-{model_name}.keras'),\n",
    "        save_best_only=True\n",
    "    )\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        os.path.join(logdir, f'logs-{model_name}.keras'),    \n",
    "    )\n",
    "\n",
    "    return model_checkpoint_callback, tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "172fa6f5-7162-42b5-adf4-3a4d3ddad934",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844e36e-34a4-4a42-8818-96d88ad9ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1701/2971\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 45ms/step - binary_accuracy: 0.9423 - loss: 0.2003"
     ]
    }
   ],
   "source": [
    "for index in range(0, len(models)):\n",
    "    model = models[index]\n",
    "    model_name = models_params[index]['name']\n",
    "    \n",
    "    model_checkpoint_callback, tensorboard_callback = get_callbacks(model_name)\n",
    "    \n",
    "    history = model.fit(train, validation_data=test, epochs=EPOCHS, callbacks=[model_checkpoint_callback, tensorboard_callback])\n",
    "\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d19d6cb-a4b7-415e-9dc6-da3623c5a295",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d9afd3-afb6-4549-9a9f-4eb6102694e1",
   "metadata": {},
   "source": [
    "Evaluate the models you trained on the test datasets. Plot ROC curves for each label (use `sklearn.metrics.RocCurveDisplay`) for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331fc5c-5d19-4fa8-a5e1-3216d9d4457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    model: keras.Model,\n",
    "    ax: plt.Axes | None = None\n",
    ") -> float:\n",
    "    '''Plots ROC curves for each of the labels (on a single axes) and outputs mean ROC AUC score.\n",
    "\n",
    "    Arguments:\n",
    "        X: model inputs\n",
    "        y: ground thruths\n",
    "        model: model to plot the curve for\n",
    "        ax: axes to plot on\n",
    "\n",
    "    Returns:\n",
    "        Mean ROC AUC score'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38c983-510f-47f5-8a11-5344b53c15e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "224c37b8-218a-43d8-b056-2389a3869e8c",
   "metadata": {},
   "source": [
    "Plot the mean ROC AUC scores. Which model has the highest score? On what kind of dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2b2c8-66ec-40e9-aaec-07ac79c86ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f56b9bca-296b-45cd-be57-6027371d0c5a",
   "metadata": {},
   "source": [
    "Inspect the best model performance closer. Come up with some sentences (in English). Does the model output sensible results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f66686-4319-4762-82d0-963edbad5fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_text(text: str, model: keras.Model, threshold: float = 0.5, max_length: int | None = None) -> list[str]:\n",
    "    '''Computes the model output for `text` and outputs a list of emotions that have a probability of at least `threshold`\n",
    "\n",
    "    Arguments:\n",
    "        text: text to label\n",
    "        model: model to use\n",
    "        threshold: threshold to use\n",
    "        max_length: max length for tokenization\n",
    "    \n",
    "    Return:\n",
    "        List of predicted emotion labels'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59fe95-b472-4b7b-95f9-23d17bba18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emotion_scores(text: str, model: keras.Model, max_length: int | None = None, ax: plt.Axes | None = None):\n",
    "    '''Plots a bar plot of emotion probabilities for given `text` using `model`.\n",
    "\n",
    "    Arguments:\n",
    "        text: text to label\n",
    "        model: model to use        \n",
    "        max_length: max length for tokenization\n",
    "        ax: axes to plot on'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7a3fd-d086-47da-ab93-4927079cd037",
   "metadata": {},
   "source": [
    "For each of your texts get a list of emotion labels and plot emotion scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae81dd-ab9c-46a0-825f-ab53b367b75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c98b8e7f-e826-497c-943a-fe944a4f4ba9",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa03eefa-90f1-4be9-9ab0-b17e85993aa1",
   "metadata": {},
   "source": [
    "Train and evaluate the same model as your best one, but use a different cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1a9da-b0a9-4a4d-9d91-b7061fc903b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
